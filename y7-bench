#!/bin/bash
# ─────────────────────────────────────────────────────────────
#  y7-bench — Y7 OS Model Benchmark Tool
#  Test speed, quality, and Arabic capability of local models
#  github.com/yahyasaqban-lab/y7os
# ─────────────────────────────────────────────────────────────

BLUE='\033[0;34m'; GREEN='\033[0;32m'; YELLOW='\033[1;33m'
CYAN='\033[0;36m'; RED='\033[0;31m'; BOLD='\033[1m'; DIM='\033[2m'; NC='\033[0m'

Y7_BENCH_DIR="${Y7_BENCH_DIR:-/ai/benchmarks}"
OLLAMA_HOST="${OLLAMA_HOST:-http://localhost:11434}"

log_ok()   { echo -e "  ${GREEN}✅${NC}  $1"; }
log_info() { echo -e "  ${CYAN}ℹ️ ${NC}  $1"; }
log_warn() { echo -e "  ${YELLOW}⚠️ ${NC}  $1"; }

# ── Test prompts ──────────────────────────────────────────────
PROMPT_SPEED="Count from 1 to 20."
PROMPT_REASONING="What is 15% of 240? Show your working."
PROMPT_ARABIC="اكتب جملة قصيرة باللغة العربية عن الذكاء الاصطناعي."
PROMPT_CODE="Write a Python function that reverses a string."
PROMPT_SUMMARY="Summarize in one sentence: The quick brown fox jumps over the lazy dog near the river bank on a sunny afternoon."

# ── Run single benchmark ──────────────────────────────────────
run_bench() {
  local model="$1"
  local prompt="$2"
  local label="$3"

  local start end elapsed tokens_approx tps response

  start=$(date +%s%N)
  response=$(curl -s "$OLLAMA_HOST/api/generate" \
    -d "{\"model\": \"$model\", \"prompt\": \"$prompt\", \"stream\": false}" \
    2>/dev/null | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('response','ERROR'))" 2>/dev/null || echo "ERROR")
  end=$(date +%s%N)

  elapsed=$(( (end - start) / 1000000 ))  # ms
  local elapsed_s=$(echo "scale=1; $elapsed/1000" | bc 2>/dev/null || echo "?")

  # Estimate tokens (rough: 1 token ≈ 4 chars)
  local char_count=${#response}
  tokens_approx=$(( char_count / 4 ))
  if [ "$elapsed" -gt 0 ]; then
    tps=$(echo "scale=1; $tokens_approx * 1000 / $elapsed" | bc 2>/dev/null || echo "?")
  else
    tps="?"
  fi

  # Score quality (simple heuristic)
  local quality="?"
  if [ "$char_count" -gt 10 ] && [ "$response" != "ERROR" ]; then
    if [ "$char_count" -gt 100 ]; then quality="Good"
    elif [ "$char_count" -gt 30 ]; then quality="OK"
    else quality="Short"
    fi
  elif [ "$response" = "ERROR" ]; then
    quality="Failed"
  fi

  printf "  %-22s  %6s tok/s  %6ss  %s\n" "$label" "$tps" "$elapsed_s" "$quality"

  # Save to results
  echo "$model|$label|$tps|$elapsed_s|$quality|$response" >> "$Y7_BENCH_DIR/results.csv" 2>/dev/null || true
}

# ── Benchmark a single model ──────────────────────────────────
bench_model() {
  local model="$1"

  # Check model exists
  if ! ollama list 2>/dev/null | grep -q "$(echo $model | cut -d: -f1)"; then
    log_warn "Model '$model' not downloaded — skipping"
    return
  fi

  echo ""
  echo -e "  ${BOLD}${BLUE}Benchmarking: $model${NC}"
  echo "  ──────────────────────────────────────────────────────"
  printf "  %-22s  %9s  %8s  %s\n" "Test" "Speed" "Time" "Quality"
  printf "  %s\n" "──────────────────────────────────────────────────────"

  run_bench "$model" "$PROMPT_SPEED"     "Speed (counting)"
  run_bench "$model" "$PROMPT_REASONING" "Reasoning (math)"
  run_bench "$model" "$PROMPT_CODE"      "Code (Python)"
  run_bench "$model" "$PROMPT_SUMMARY"   "Summarization"
  run_bench "$model" "$PROMPT_ARABIC"    "Arabic response"

  echo ""
}

# ── Benchmark all installed models ───────────────────────────
bench_all() {
  echo ""
  echo -e "${BOLD}  Y7 OS Model Benchmark${NC}"
  echo -e "  ${DIM}Testing all downloaded models...${NC}"

  mkdir -p "$Y7_BENCH_DIR"
  echo "model|test|tps|time_s|quality|response" > "$Y7_BENCH_DIR/results.csv"

  local models
  models=$(ollama list 2>/dev/null | grep -v "^NAME" | awk '{print $1}')

  if [ -z "$models" ]; then
    log_warn "No models downloaded. Run: y7-models download phi3"
    exit 1
  fi

  for model in $models; do
    bench_model "$model"
  done

  print_summary
}

# ── Quick speed test ──────────────────────────────────────────
bench_quick() {
  local model="${1:-phi3:mini}"
  echo ""
  echo -e "  ${BOLD}Quick benchmark: $model${NC}"
  echo "  ─────────────────────────────────────────────"

  local start end elapsed response tokens_approx tps

  # Warm up
  log_info "Warming up..."
  curl -s "$OLLAMA_HOST/api/generate" \
    -d "{\"model\": \"$model\", \"prompt\": \"Hi\", \"stream\": false}" \
    &>/dev/null || true

  # Actual test
  log_info "Running speed test..."
  start=$(date +%s%N)
  response=$(curl -s "$OLLAMA_HOST/api/generate" \
    -d "{\"model\": \"$model\", \"prompt\": \"$PROMPT_SPEED\", \"stream\": false}" \
    2>/dev/null | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('response',''))" 2>/dev/null)
  end=$(date +%s%N)

  elapsed=$(( (end - start) / 1000000 ))
  tokens_approx=$(( ${#response} / 4 ))
  tps=$(echo "scale=1; $tokens_approx * 1000 / $elapsed" | bc 2>/dev/null || echo "?")

  echo ""
  log_ok "Model:  $model"
  log_ok "Speed:  ~${tps} tokens/sec"
  log_ok "Time:   $(echo "scale=1; $elapsed/1000" | bc)s"
  log_ok "RAM:    $(free -m | awk '/^Mem:/{print $2-$7}')MB used"
  echo ""
  echo -e "  ${BOLD}Response preview:${NC}"
  echo "$response" | head -3 | sed 's/^/  /'
  echo ""
}

# ── Arabic quality test ───────────────────────────────────────
bench_arabic() {
  local model="${1:-}"

  echo ""
  echo -e "  ${BOLD}Arabic Language Test${NC}"
  echo "  ─────────────────────────────────────────────"

  # Get all models or just the one specified
  local models
  if [ -n "$model" ]; then
    models="$model"
  else
    models=$(ollama list 2>/dev/null | grep -v "^NAME" | awk '{print $1}')
  fi

  local prompts=(
    "اكتب جملة قصيرة عن الذكاء الاصطناعي"
    "ما هو الفرق بين التعلم الآلي والذكاء الاصطناعي؟"
    "اشرح كيف يعمل نظام التشغيل لينكس بالعربية"
  )

  for m in $models; do
    echo ""
    echo -e "  ${CYAN}Model: $m${NC}"
    for prompt in "${prompts[@]}"; do
      echo -e "  ${DIM}Q: $prompt${NC}"
      local resp
      resp=$(curl -s "$OLLAMA_HOST/api/generate" \
        -d "{\"model\": \"$m\", \"prompt\": \"$prompt\", \"stream\": false}" \
        2>/dev/null | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('response','')[:200])" 2>/dev/null)
      echo "  A: $resp"
      echo ""
    done
  done
}

# ── Print benchmark summary ───────────────────────────────────
print_summary() {
  local results="$Y7_BENCH_DIR/results.csv"
  [ ! -f "$results" ] && return

  echo ""
  echo -e "${BOLD}  Benchmark Summary${NC}"
  echo "  ─────────────────────────────────────────────"
  echo ""

  # Find fastest model overall
  local fastest
  fastest=$(tail -n +2 "$results" | sort -t'|' -k3 -rn | head -1 | cut -d'|' -f1)
  [ -n "$fastest" ] && log_ok "Fastest model: ${CYAN}$fastest${NC}"

  # Best Arabic
  local best_arabic
  best_arabic=$(tail -n +2 "$results" | grep "Arabic" | sort -t'|' -k5 | grep "Good" | head -1 | cut -d'|' -f1)
  [ -n "$best_arabic" ] && log_ok "Best Arabic:   ${CYAN}$best_arabic${NC}"

  echo ""
  log_info "Full results saved: $results"
  echo ""
}

show_help() {
  echo ""
  echo -e "${BOLD}  y7-bench — Y7 OS Model Benchmark${NC}"
  echo ""
  echo -e "  ${CYAN}y7-bench all${NC}               Benchmark all downloaded models"
  echo -e "  ${CYAN}y7-bench quick [model]${NC}     Quick speed test"
  echo -e "  ${CYAN}y7-bench arabic [model]${NC}    Test Arabic language quality"
  echo -e "  ${CYAN}y7-bench model <name>${NC}      Full benchmark on one model"
  echo -e "  ${CYAN}y7-bench summary${NC}           Show last benchmark results"
  echo ""
  echo -e "  ${DIM}Results saved to: /ai/benchmarks/results.csv${NC}"
  echo ""
}

# ── Check Ollama is running ───────────────────────────────────
check_ollama() {
  if ! curl -s "$OLLAMA_HOST" &>/dev/null; then
    log_warn "Ollama not running. Starting..."
    ollama serve &>/dev/null & sleep 3
    curl -s "$OLLAMA_HOST" &>/dev/null || { echo "Could not start Ollama"; exit 1; }
  fi
}

# ── Router ────────────────────────────────────────────────────
case "${1:-help}" in
  all)     check_ollama; bench_all ;;
  quick)   check_ollama; bench_quick "${2:-phi3:mini}" ;;
  arabic)  check_ollama; bench_arabic "${2:-}" ;;
  model)   check_ollama; bench_model "${2:-phi3:mini}" ;;
  summary) print_summary ;;
  help|--help|-h) show_help ;;
  *)       log_warn "Unknown: $1"; show_help ;;
esac
