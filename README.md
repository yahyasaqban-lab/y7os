<div align="center">

<h1>ğŸ¤– Y7 OS</h1>

<p><strong>The AI-first Linux distro for low-resource hardware.</strong><br/>
<em>ØªÙˆØ²ÙŠØ¹Ø© Ù„ÙŠÙ†ÙƒØ³ Ù…Ø®ØµØµØ© Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù…Ø­Ø¯ÙˆØ¯Ø© Ø§Ù„Ù…ÙˆØ§Ø±Ø¯.</em></p>

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Status: Planning](https://img.shields.io/badge/Status-Planning-yellow.svg)]()
[![Arabic Support](https://img.shields.io/badge/Language-Arabic%20%2B%20English-green.svg)]()
[![Privacy First](https://img.shields.io/badge/Privacy-100%25%20Local-red.svg)]()
[![Platform](https://img.shields.io/badge/Platform-x86__64%20%7C%20ARM-lightgrey.svg)]()

</div>

---

## ğŸ‡¬ğŸ‡§ English

### What is Y7 OS?

Y7 OS is an AI-first Linux distribution built from scratch for people who want to run local AI on **any hardware** â€” without a GPU, without a cloud subscription, and without compromising privacy.

It runs on old laptops, Raspberry Pi, VPS servers, and ARM single-board computers. It speaks Arabic and English natively. And it installs with one command.

### âœ¨ Key Features

- ğŸ§  **Local AI by default** â€” Ollama + llama.cpp + Open WebUI pre-configured
- âš¡ **Low-resource optimized** â€” runs on 4GB RAM with ZRAM compression
- ğŸŒ **Arabic & English native** â€” full RTL support, bilingual interface
- ğŸ”’ **Privacy-first** â€” zero telemetry, zero cloud, works fully offline
- ğŸ”„ **Adaptive backend** â€” auto-switches AI engine based on available RAM
- ğŸ› ï¸ **Developer-ready** â€” Python, Git, Docker pre-installed
- ğŸ“¦ **One-command install** â€” zero configuration required

### ğŸš€ Quick Start

```bash
curl -fsSL https://raw.githubusercontent.com/yahyasaqban-lab/y7os/main/tools/y7-install | bash
```

> âš ï¸ **Status:** Y7 OS is currently in the planning/early development stage. The install script is not yet available. Star the repo to follow progress.

### ğŸ’» Hardware Support

| Device | Min RAM | Recommended Model | Backend |
|---|---|---|---|
| Raspberry Pi 4/5 | 4 GB | Phi-3 Mini | llama.cpp |
| Old Laptop (Intel) | 4 GB | Mistral 7B Q4 | llama.cpp / Ollama |
| Old Laptop (AMD) | 8 GB | Llama 3.1 8B Q4 | Ollama |
| VPS (2â€“4 vCPU) | 4 GB | Phi-3 / TinyLlama | llama.cpp headless |
| Modern Laptop | 16 GB | Llama 3.1 70B Q4 | Ollama |

### ğŸ§± Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 4 â€” Y7 Shell                         â”‚
â”‚  y7-cli  â€¢  y7-models  â€¢  y7-ai             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 3 â€” AI Stack                         â”‚
â”‚  Ollama  â€¢  llama.cpp  â€¢  Open WebUI        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 2 â€” Runtime                          â”‚
â”‚  Python 3.11  â€¢  Docker  â€¢  Git             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 1 â€” Base                             â”‚
â”‚  LFS Kernel  â€¢  musl libc  â€¢  BusyBox       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ—ºï¸ Roadmap

| Version | Goal | Status |
|---|---|---|
| v0.1 | y7-install script works on Ubuntu/Debian | ğŸ”„ In Progress |
| v0.2 | Full AI stack auto-configured + Open WebUI | ğŸ“‹ Planned |
| v0.5 | y7-models CLI + y7-status + Arabic support | ğŸ“‹ Planned |
| v0.8 | Custom LFS kernel + minimal base image | ğŸ“‹ Planned |
| v0.9 | Bootable ISO, tested on 5+ hardware targets | ğŸ“‹ Planned |
| v1.0 | Public release + full documentation | ğŸ“‹ Planned |

### ğŸ¤ Contributing

Y7 OS is open to contributors at all levels. See [CONTRIBUTING.md](docs/contributing.md) for how to help.

Areas we need help with:
- Shell scripting (y7-install, y7-models)
- ARM hardware testing (Raspberry Pi)
- Arabic localization
- Documentation

### ğŸ“„ License

MIT â€” free forever, for everyone.

---

## ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

### Ù…Ø§ Ù‡Ùˆ Y7 OSØŸ

Y7 OS Ù‡Ùˆ Ù†Ø¸Ø§Ù… ØªØ´ØºÙŠÙ„ Ù„ÙŠÙ†ÙƒØ³ Ù…Ø¨Ù†ÙŠ Ù…Ù† Ø§Ù„ØµÙØ±ØŒ Ù…ØµÙ…Ù… Ø®ØµÙŠØµØ§Ù‹ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø¹Ù„Ù‰ **Ø£ÙŠ Ø¬Ù‡Ø§Ø²** â€” Ø¨Ø¯ÙˆÙ† ÙƒØ§Ø±Øª Ø´Ø§Ø´Ø© Ù‚ÙˆÙŠØŒ Ø¨Ø¯ÙˆÙ† Ø§Ø´ØªØ±Ø§Ùƒ Ø³Ø­Ø§Ø¨ÙŠØŒ ÙˆØ¨Ø¯ÙˆÙ† Ø§Ù„ØªÙ†Ø§Ø²Ù„ Ø¹Ù† Ø§Ù„Ø®ØµÙˆØµÙŠØ©.

ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù„Ø§Ø¨ØªÙˆØ¨Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©ØŒ ÙˆRaspberry PiØŒ ÙˆØ®ÙˆØ§Ø¯Ù… VPSØŒ ÙˆØ£Ø¬Ù‡Ø²Ø© ARM. ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¨Ø´ÙƒÙ„ Ø£ØµÙ„ÙŠ. ÙˆÙŠÙØ«Ø¨ÙÙ‘Øª Ø¨Ø£Ù…Ø± ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·.

### âœ¨ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

- ğŸ§  **Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø­Ù„ÙŠ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„** â€” Ollama + llama.cpp + Open WebUI Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
- âš¡ **Ù…Ø­Ø³Ù‘Ù† Ù„Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù…Ø­Ø¯ÙˆØ¯Ø©** â€” ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ 4GB RAM Ù…Ø¹ Ø¶ØºØ· ZRAM
- ğŸŒ **Ø¹Ø±Ø¨ÙŠ ÙˆØ¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ø£ØµÙ„ÙŠ** â€” Ø¯Ø¹Ù… ÙƒØ§Ù…Ù„ Ù„Ù„ÙƒØªØ§Ø¨Ø© Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ù„Ù„ÙŠØ³Ø§Ø±
- ğŸ”’ **Ø§Ù„Ø®ØµÙˆØµÙŠØ© Ø£ÙˆÙ„Ø§Ù‹** â€” Ø¨Ø¯ÙˆÙ† Ø¥Ø±Ø³Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙŠØ¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† Ø¥Ù†ØªØ±Ù†Øª
- ğŸ”„ **ØªØ¨Ø¯ÙŠÙ„ Ø°ÙƒÙŠ Ù„Ù„Ù…Ø­Ø±Ùƒ** â€” ÙŠØ®ØªØ§Ø± Ø£ÙØ¶Ù„ Ù…Ø­Ø±Ùƒ AI Ø­Ø³Ø¨ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©
- ğŸ› ï¸ **Ø¬Ø§Ù‡Ø² Ù„Ù„Ù…Ø·ÙˆØ±ÙŠÙ†** â€” Python ÙˆGit ÙˆDocker Ù…Ø«Ø¨ØªØ© Ù…Ø³Ø¨Ù‚Ø§Ù‹
- ğŸ“¦ **ØªØ«Ø¨ÙŠØª Ø¨Ø£Ù…Ø± ÙˆØ§Ø­Ø¯** â€” Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ø£ÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª

### ğŸš€ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©

```bash
curl -fsSL https://raw.githubusercontent.com/yahyasaqban-lab/y7os/main/tools/y7-install | bash
```

> âš ï¸ **Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:** Y7 OS ÙÙŠ Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ®Ø·ÙŠØ· ÙˆØ§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø¨ÙƒØ±. Ø§Ø¶ØºØ· Star Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„ØªÙ‚Ø¯Ù….

### ğŸ’» Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©

| Ø§Ù„Ø¬Ù‡Ø§Ø² | Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¯Ù†ÙŠØ§ | Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡ | Ø§Ù„Ù…Ø­Ø±Ùƒ |
|---|---|---|---|
| Raspberry Pi 4/5 | 4 GB | Phi-3 Mini | llama.cpp |
| Ù„Ø§Ø¨ØªÙˆØ¨ Ù‚Ø¯ÙŠÙ… (Intel) | 4 GB | Mistral 7B Q4 | llama.cpp / Ollama |
| Ù„Ø§Ø¨ØªÙˆØ¨ Ù‚Ø¯ÙŠÙ… (AMD) | 8 GB | Llama 3.1 8B Q4 | Ollama |
| VPS (2â€“4 vCPU) | 4 GB | Phi-3 / TinyLlama | llama.cpp headless |
| Ù„Ø§Ø¨ØªÙˆØ¨ Ø­Ø¯ÙŠØ« | 16 GB | Llama 3.1 70B Q4 | Ollama |

### ğŸ—ºï¸ Ø®Ø§Ø±Ø·Ø© Ø§Ù„Ø·Ø±ÙŠÙ‚

| Ø§Ù„Ø¥ØµØ¯Ø§Ø± | Ø§Ù„Ù‡Ø¯Ù | Ø§Ù„Ø­Ø§Ù„Ø© |
|---|---|---|
| v0.1 | Ø³ÙƒØ±ÙŠØ¨Øª y7-install ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ubuntu/Debian | ğŸ”„ Ù‚ÙŠØ¯ Ø§Ù„ØªØ·ÙˆÙŠØ± |
| v0.2 | ØªØ«Ø¨ÙŠØª ÙƒØ§Ù…Ù„ Ù„Ù…ÙƒØ¯Ø³ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ | ğŸ“‹ Ù…Ø®Ø·Ø· |
| v0.5 | Ø£Ø¯ÙˆØ§Øª y7-models Ùˆy7-status ÙˆØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© | ğŸ“‹ Ù…Ø®Ø·Ø· |
| v0.8 | Ù†ÙˆØ§Ø© LFS Ù…Ø®ØµØµØ© ÙˆØµÙˆØ±Ø© Ù‚Ø§Ø¹Ø¯ÙŠØ© | ğŸ“‹ Ù…Ø®Ø·Ø· |
| v1.0 | Ø¥ØµØ¯Ø§Ø± Ø¹Ø§Ù… + ØªÙˆØ«ÙŠÙ‚ ÙƒØ§Ù…Ù„ | ğŸ“‹ Ù…Ø®Ø·Ø· |

### ğŸ¤ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø©

Y7 OS Ù…ÙØªÙˆØ­ Ù„Ù„Ù…Ø³Ø§Ù‡Ù…ÙŠÙ† Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª. Ø±Ø§Ø¬Ø¹ [CONTRIBUTING.md](docs/contributing.md) Ù„Ù„Ø¨Ø¯Ø¡.

### ğŸ“„ Ø§Ù„Ø±Ø®ØµØ©

MIT â€” Ù…Ø¬Ø§Ù†ÙŠ Ù„Ù„Ø¬Ù…ÙŠØ¹ØŒ Ù„Ù„Ø£Ø¨Ø¯.

---

<div align="center">

**Built by Yahya â€” For everyone â€” Forever open**<br/>
**Ø¨ÙÙ†ÙŠ Ø¨ÙˆØ§Ø³Ø·Ø© ÙŠØ­ÙŠÙ‰ â€” Ù„Ù„Ø¬Ù…ÙŠØ¹ â€” Ù…ÙØªÙˆØ­ Ù„Ù„Ø£Ø¨Ø¯**

[GitHub](https://github.com/yahyasaqban-lab/y7os) â€¢ [Issues](https://github.com/yahyasaqban-lab/y7os/issues) â€¢ [Discussions](https://github.com/yahyasaqban-lab/y7os/discussions)

</div>
